#!/usr/bin/env python
# -*- python -*-

import argparse
from pprint import pprint
import requests
from dlernen.config import Config


def widest_attrkey_len(result):
    """
    for output formatting purposes, return the length of the longest attrkey among the attributes in the result.

    :param result:
    :return:
    """

    # the attribute with the longest key
    longest_key = max(result['attributes'], key=lambda x: len(x['key']))
    return len(longest_key['key']) if longest_key else 0


def hanging_tag_width(result):
    return len("%s (%s)" % (result['word'], result['pos_name']))


def display_result(result, tagwidth, keywidth):

    tag = "%s (%s)" % (result['word'], result['pos_name'])
    print("%s" % ('=' * 66))

    for a in result['attributes']:
        display_key = "%s:" % a['key']
        print("%s %s %s" % (tag.ljust(tagwidth + 10),
                            display_key.ljust(keywidth + 1),  # add 1 for the : appended to the key name
                            a['value']))
        tag = ''


if __name__ == '__main__':
    parser = argparse.ArgumentParser()
    parser.add_argument("word", nargs='+', help="word to look up")
    parser.add_argument("--partial", action='store_true',
                        help="search for word verbatim, no substring matching")
    args = parser.parse_args()

    all_results = []
    for word in args.word:
        url = "%s/api/word/%s?partial=%s" % (Config.BASE_URL, word, str(args.partial))
        r = requests.get(url)
        results = r.json()
        if not results:
            print("%s NOT FOUND:  %s" % ('#' * 33, word))

        all_results += results

    if all_results:
        keywidth = max([widest_attrkey_len(x) for x in all_results])
        tagwidth = max([hanging_tag_width(x) for x in all_results])

        for result in all_results:
            display_result(result, tagwidth, keywidth)

    # TODO:  record lookups in the lookup table.  need one post request for all word ids looked up.
    # beware that --partial with multiple args might cause some words to be double-counted, so need
    # to turn the word_ids into a set before posting.
    #
    #     q = """
    # insert into lookup (word_id) values (%s)
    # on duplicate key update count = count + 1
    # """
    #     c.executemany(q, matched_ids)
    #     db.commit()
